{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab69029-fa85-4a7f-a969-adef33bfa802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6691fe-1aff-4c8e-8279-a811a7c17f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "excel_file_path = 'chennai_cars.xlsx'\n",
    "csv_file_path = 'chennai_cars.csv'\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(excel_file_path, sheet_name='chennai_cars.csv')  # Adjust sheet_name as needed\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)  # Save without row index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f31ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "excel_file_path = 'bangalore_cars.xlsx'\n",
    "csv_file_path = 'bangalore_cars.csv'\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(excel_file_path, sheet_name='bangalore_cars.csv')  # Adjust sheet_name as needed\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)  # Save without row index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be9ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "excel_file_path = 'delhi_cars.xlsx'\n",
    "csv_file_path = 'delhi_cars.csv'\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(excel_file_path, sheet_name='delhi_cars.csv')  # Adjust sheet_name as needed\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)  # Save without row index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ee1cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "excel_file_path = 'jaipur_cars.xlsx'\n",
    "csv_file_path = 'jaipur_cars.csv'\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(excel_file_path, sheet_name='jaipur_cars.csv')  # Adjust sheet_name as needed\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)  # Save without row index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22bc7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "excel_file_path = 'hyderabad_cars.xlsx'\n",
    "csv_file_path = 'hyderabad_cars.csv'\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(excel_file_path, sheet_name='hyderabad_cars.csv')  # Adjust sheet_name as needed\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)  # Save without row index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd73196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "excel_file_path = 'kolkata_cars.xlsx'\n",
    "csv_file_path = 'kolkata_cars.csv'\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(excel_file_path, sheet_name='kolkata_cars.csv')  # Adjust sheet_name as needed\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)  # Save without row index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a184751f-26c6-4b83-a458-45fad73f72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bangalore = pd.read_csv('bangalore_cars.csv')\n",
    "df_chennai = pd.read_csv('chennai_cars.csv')\n",
    "df_delhi = pd.read_csv('delhi_cars.csv')\n",
    "df_hyderabad = pd.read_csv('hyderabad_cars.csv')\n",
    "df_jaipur = pd.read_csv('jaipur_cars.csv')\n",
    "df_kolkata = pd.read_csv('kolkata_cars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8181aea2",
   "metadata": {},
   "source": [
    "### Final codes to split all keys and values as a separated columns for all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b58c741-dca6-4e0b-bd54-7011a91af5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['new_car_detail', 'new_car_overview', 'new_car_feature',\n",
      "       'new_car_specs', 'car_links'],\n",
      "      dtype='object')\n",
      "\n",
      "Combined DataFrames have been saved to 'bangalore_cars_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('bangalore_cars.csv')\n",
    "\n",
    "# Display the columns to confirm their presence\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# ---- Helper Functions ----\n",
    "\n",
    "# Function to convert a string to a dictionary\n",
    "def convert_to_dict(value):\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return {}\n",
    "\n",
    "# Function to flatten a dictionary\n",
    "def flatten_dict(d):\n",
    "    flattened = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            for sub_k, sub_v in flatten_dict(v).items():\n",
    "                flattened[f\"{k}_{sub_k}\"] = sub_v\n",
    "        else:\n",
    "            flattened[k] = v\n",
    "    return flattened\n",
    "\n",
    "# Function to extract and flatten the nested 'top' dictionary\n",
    "def extract_flatten_dict(nested_dict):\n",
    "    if 'top' in nested_dict:\n",
    "        top_data = nested_dict['top']\n",
    "        df = pd.DataFrame(top_data)\n",
    "        df = df.drop(columns=['icon'], errors='ignore')\n",
    "        return df.set_index('key').T\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to flatten the nested 'top' and 'data' sections\n",
    "def flatten_nested_data(nested_dict):\n",
    "    # Flatten 'top' section\n",
    "    top_df = pd.DataFrame(nested_dict.get('top', []))\n",
    "    \n",
    "    # Flatten 'data' section\n",
    "    data_list = nested_dict.get('data', [])\n",
    "    data_df_list = []\n",
    "    for category in data_list:\n",
    "        category_df = pd.DataFrame(category.get('list', []))\n",
    "        category_df['heading'] = category.get('heading')\n",
    "        category_df['subHeading'] = category.get('subHeading')\n",
    "        data_df_list.append(category_df)\n",
    "    \n",
    "    data_df = pd.concat(data_df_list, ignore_index=True) if data_df_list else pd.DataFrame()\n",
    "    \n",
    "    # Add commonIcon\n",
    "    common_icon = nested_dict.get('commonIcon', None)\n",
    "    if not top_df.empty:\n",
    "        top_df['commonIcon'] = common_icon\n",
    "    if not data_df.empty:\n",
    "        data_df['commonIcon'] = common_icon\n",
    "\n",
    "    return top_df, data_df\n",
    "\n",
    "# ---- Process 'new_car_detail' Column ----\n",
    "\n",
    "# Fetch the 'new_car_detail' column only\n",
    "new_car_detail_column = df['new_car_detail']\n",
    "\n",
    "# Apply conversion function to the 'new_car_detail' column\n",
    "new_car_detail_dicts = new_car_detail_column.apply(convert_to_dict)\n",
    "\n",
    "# Flatten each dictionary and convert to DataFrame\n",
    "flattened_df_list = [pd.DataFrame([flatten_dict(d)]) for d in new_car_detail_dicts]\n",
    "flattened_df = pd.concat(flattened_df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_overview' Column ----\n",
    "\n",
    "# Convert the 'new_car_overview' column from string to nested dictionaries\n",
    "df['new_car_overview'] = df['new_car_overview'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Extract and flatten the nested dictionaries\n",
    "df_list = [extract_flatten_dict(d) for d in df['new_car_overview']]\n",
    "df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_feature' Column ----\n",
    "\n",
    "# Convert the 'new_car_feature' column from string to nested dictionaries\n",
    "df['new_car_feature'] = df['new_car_feature'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Apply the flattening function to each row and collect results\n",
    "top_dfs_feature = []\n",
    "data_dfs_feature = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    top_df_feature, data_df_feature = flatten_nested_data(row['new_car_feature'])\n",
    "    top_dfs_feature.append(top_df_feature)\n",
    "    data_dfs_feature.append(data_df_feature)\n",
    "\n",
    "top_combined_feature = pd.concat(top_dfs_feature, ignore_index=True)\n",
    "data_combined_feature = pd.concat(data_dfs_feature, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_specs' Column ----\n",
    "\n",
    "# Initialize a list to collect key-value pairs with an index reference\n",
    "data_records = []\n",
    "\n",
    "# Define the processing function for extracting key-value pairs with an index reference\n",
    "def extract_key_value_pairs(json_data, index):\n",
    "    try:\n",
    "        # Convert JSON-like string into a dictionary\n",
    "        data = json.loads(json_data.replace(\"'\", \"\\\"\"))\n",
    "\n",
    "        # Create a dictionary to hold the values for this record\n",
    "        record = {'index': index}\n",
    "        \n",
    "        # Extract 'top' section key-value pairs\n",
    "        if 'top' in data:\n",
    "            for item in data['top']:\n",
    "                record[item['key']] = item['value']\n",
    "\n",
    "        # Extract 'data' section key-value pairs\n",
    "        if 'data' in data:\n",
    "            for section in data['data']:\n",
    "                for item in section['list']:\n",
    "                    record[item['key']] = item['value']\n",
    "        \n",
    "        # Add the record to the list\n",
    "        data_records.append(record)\n",
    "    \n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error processing JSON data at index {index}: {e}\")\n",
    "\n",
    "# Process only the 'new_car_specs' column\n",
    "if 'new_car_specs' in df.columns:\n",
    "    for index, row in df.iterrows():\n",
    "        json_data = row['new_car_specs']\n",
    "        if pd.notna(json_data):  # Check for NaN values\n",
    "            extract_key_value_pairs(json_data, index)\n",
    "\n",
    "# Create a DataFrame from the list of records\n",
    "records_df = pd.DataFrame(data_records)\n",
    "\n",
    "# Drop the 'index' column as it's not needed in the final output\n",
    "records_df = records_df.drop(columns=['index'], errors='ignore')\n",
    "\n",
    "# ---- Combine All DataFrames Horizontally ----\n",
    "\n",
    "# Reset index for consistency\n",
    "flattened_df.reset_index(drop=True, inplace=True)\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "top_combined_feature.reset_index(drop=True, inplace=True)\n",
    "data_combined_feature.reset_index(drop=True, inplace=True)\n",
    "records_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate all DataFrames horizontally\n",
    "max_len = max(len(flattened_df), len(df_combined), len(top_combined_feature), len(data_combined_feature), len(records_df))\n",
    "\n",
    "# Ensure all DataFrames have the same number of rows by reindexing\n",
    "flattened_df = flattened_df.reindex(range(max_len))\n",
    "df_combined = df_combined.reindex(range(max_len))\n",
    "top_combined_feature = top_combined_feature.reindex(range(max_len))\n",
    "data_combined_feature = data_combined_feature.reindex(range(max_len))\n",
    "records_df = records_df.reindex(range(max_len))\n",
    "\n",
    "# Concatenate horizontally\n",
    "final_df = pd.concat([flattened_df, df_combined, top_combined_feature, data_combined_feature, records_df], axis=1)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv('bangalore_cars_output.csv', index=False)\n",
    "\n",
    "print(\"\\nCombined DataFrames have been saved to 'bangalore_cars_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9971d67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['new_car_detail', 'new_car_overview', 'new_car_feature',\n",
      "       'new_car_specs', 'car_links'],\n",
      "      dtype='object')\n",
      "\n",
      "Combined DataFrames have been saved to 'chennai_cars_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('chennai_cars.csv')\n",
    "\n",
    "# Display the columns to confirm their presence\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# ---- Helper Functions ----\n",
    "\n",
    "# Function to convert a string to a dictionary\n",
    "def convert_to_dict(value):\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return {}\n",
    "\n",
    "# Function to flatten a dictionary\n",
    "def flatten_dict(d):\n",
    "    flattened = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            for sub_k, sub_v in flatten_dict(v).items():\n",
    "                flattened[f\"{k}_{sub_k}\"] = sub_v\n",
    "        else:\n",
    "            flattened[k] = v\n",
    "    return flattened\n",
    "\n",
    "# Function to extract and flatten the nested 'top' dictionary\n",
    "def extract_flatten_dict(nested_dict):\n",
    "    if 'top' in nested_dict:\n",
    "        top_data = nested_dict['top']\n",
    "        df = pd.DataFrame(top_data)\n",
    "        df = df.drop(columns=['icon'], errors='ignore')\n",
    "        return df.set_index('key').T\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to flatten the nested 'top' and 'data' sections\n",
    "def flatten_nested_data(nested_dict):\n",
    "    # Flatten 'top' section\n",
    "    top_df = pd.DataFrame(nested_dict.get('top', []))\n",
    "    \n",
    "    # Flatten 'data' section\n",
    "    data_list = nested_dict.get('data', [])\n",
    "    data_df_list = []\n",
    "    for category in data_list:\n",
    "        category_df = pd.DataFrame(category.get('list', []))\n",
    "        category_df['heading'] = category.get('heading')\n",
    "        category_df['subHeading'] = category.get('subHeading')\n",
    "        data_df_list.append(category_df)\n",
    "    \n",
    "    data_df = pd.concat(data_df_list, ignore_index=True) if data_df_list else pd.DataFrame()\n",
    "    \n",
    "    # Add commonIcon\n",
    "    common_icon = nested_dict.get('commonIcon', None)\n",
    "    if not top_df.empty:\n",
    "        top_df['commonIcon'] = common_icon\n",
    "    if not data_df.empty:\n",
    "        data_df['commonIcon'] = common_icon\n",
    "\n",
    "    return top_df, data_df\n",
    "\n",
    "# ---- Process 'new_car_detail' Column ----\n",
    "\n",
    "# Fetch the 'new_car_detail' column only\n",
    "new_car_detail_column = df['new_car_detail']\n",
    "\n",
    "# Apply conversion function to the 'new_car_detail' column\n",
    "new_car_detail_dicts = new_car_detail_column.apply(convert_to_dict)\n",
    "\n",
    "# Flatten each dictionary and convert to DataFrame\n",
    "flattened_df_list = [pd.DataFrame([flatten_dict(d)]) for d in new_car_detail_dicts]\n",
    "flattened_df = pd.concat(flattened_df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_overview' Column ----\n",
    "\n",
    "# Convert the 'new_car_overview' column from string to nested dictionaries\n",
    "df['new_car_overview'] = df['new_car_overview'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Extract and flatten the nested dictionaries\n",
    "df_list = [extract_flatten_dict(d) for d in df['new_car_overview']]\n",
    "df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_feature' Column ----\n",
    "\n",
    "# Convert the 'new_car_feature' column from string to nested dictionaries\n",
    "df['new_car_feature'] = df['new_car_feature'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Apply the flattening function to each row and collect results\n",
    "top_dfs_feature = []\n",
    "data_dfs_feature = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    top_df_feature, data_df_feature = flatten_nested_data(row['new_car_feature'])\n",
    "    top_dfs_feature.append(top_df_feature)\n",
    "    data_dfs_feature.append(data_df_feature)\n",
    "\n",
    "top_combined_feature = pd.concat(top_dfs_feature, ignore_index=True)\n",
    "data_combined_feature = pd.concat(data_dfs_feature, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_specs' Column ----\n",
    "\n",
    "# Initialize a list to collect key-value pairs with an index reference\n",
    "data_records = []\n",
    "\n",
    "# Define the processing function for extracting key-value pairs with an index reference\n",
    "def extract_key_value_pairs(json_data, index):\n",
    "    try:\n",
    "        # Convert JSON-like string into a dictionary\n",
    "        data = json.loads(json_data.replace(\"'\", \"\\\"\"))\n",
    "\n",
    "        # Create a dictionary to hold the values for this record\n",
    "        record = {'index': index}\n",
    "        \n",
    "        # Extract 'top' section key-value pairs\n",
    "        if 'top' in data:\n",
    "            for item in data['top']:\n",
    "                record[item['key']] = item['value']\n",
    "\n",
    "        # Extract 'data' section key-value pairs\n",
    "        if 'data' in data:\n",
    "            for section in data['data']:\n",
    "                for item in section['list']:\n",
    "                    record[item['key']] = item['value']\n",
    "        \n",
    "        # Add the record to the list\n",
    "        data_records.append(record)\n",
    "    \n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error processing JSON data at index {index}: {e}\")\n",
    "\n",
    "# Process only the 'new_car_specs' column\n",
    "if 'new_car_specs' in df.columns:\n",
    "    for index, row in df.iterrows():\n",
    "        json_data = row['new_car_specs']\n",
    "        if pd.notna(json_data):  # Check for NaN values\n",
    "            extract_key_value_pairs(json_data, index)\n",
    "\n",
    "# Create a DataFrame from the list of records\n",
    "records_df = pd.DataFrame(data_records)\n",
    "\n",
    "# Drop the 'index' column as it's not needed in the final output\n",
    "records_df = records_df.drop(columns=['index'], errors='ignore')\n",
    "\n",
    "# ---- Combine All DataFrames Horizontally ----\n",
    "\n",
    "# Reset index for consistency\n",
    "flattened_df.reset_index(drop=True, inplace=True)\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "top_combined_feature.reset_index(drop=True, inplace=True)\n",
    "data_combined_feature.reset_index(drop=True, inplace=True)\n",
    "records_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate all DataFrames horizontally\n",
    "max_len = max(len(flattened_df), len(df_combined), len(top_combined_feature), len(data_combined_feature), len(records_df))\n",
    "\n",
    "# Ensure all DataFrames have the same number of rows by reindexing\n",
    "flattened_df = flattened_df.reindex(range(max_len))\n",
    "df_combined = df_combined.reindex(range(max_len))\n",
    "top_combined_feature = top_combined_feature.reindex(range(max_len))\n",
    "data_combined_feature = data_combined_feature.reindex(range(max_len))\n",
    "records_df = records_df.reindex(range(max_len))\n",
    "\n",
    "# Concatenate horizontally\n",
    "final_df = pd.concat([flattened_df, df_combined, top_combined_feature, data_combined_feature, records_df], axis=1)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv('chennai_cars_output.csv', index=False)\n",
    "\n",
    "print(\"\\nCombined DataFrames have been saved to 'chennai_cars_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb6154a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['new_car_detail', 'new_car_overview', 'new_car_feature',\n",
      "       'new_car_specs', 'car_links'],\n",
      "      dtype='object')\n",
      "\n",
      "Combined DataFrames have been saved to 'delhi_cars_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('delhi_cars.csv')\n",
    "\n",
    "# Display the columns to confirm their presence\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# ---- Helper Functions ----\n",
    "\n",
    "# Function to convert a string to a dictionary\n",
    "def convert_to_dict(value):\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return {}\n",
    "\n",
    "# Function to flatten a dictionary\n",
    "def flatten_dict(d):\n",
    "    flattened = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            for sub_k, sub_v in flatten_dict(v).items():\n",
    "                flattened[f\"{k}_{sub_k}\"] = sub_v\n",
    "        else:\n",
    "            flattened[k] = v\n",
    "    return flattened\n",
    "\n",
    "# Function to extract and flatten the nested 'top' dictionary\n",
    "def extract_flatten_dict(nested_dict):\n",
    "    if 'top' in nested_dict:\n",
    "        top_data = nested_dict['top']\n",
    "        df = pd.DataFrame(top_data)\n",
    "        df = df.drop(columns=['icon'], errors='ignore')\n",
    "        return df.set_index('key').T\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to flatten the nested 'top' and 'data' sections\n",
    "def flatten_nested_data(nested_dict):\n",
    "    # Flatten 'top' section\n",
    "    top_df = pd.DataFrame(nested_dict.get('top', []))\n",
    "    \n",
    "    # Flatten 'data' section\n",
    "    data_list = nested_dict.get('data', [])\n",
    "    data_df_list = []\n",
    "    for category in data_list:\n",
    "        category_df = pd.DataFrame(category.get('list', []))\n",
    "        category_df['heading'] = category.get('heading')\n",
    "        category_df['subHeading'] = category.get('subHeading')\n",
    "        data_df_list.append(category_df)\n",
    "    \n",
    "    data_df = pd.concat(data_df_list, ignore_index=True) if data_df_list else pd.DataFrame()\n",
    "    \n",
    "    # Add commonIcon\n",
    "    common_icon = nested_dict.get('commonIcon', None)\n",
    "    if not top_df.empty:\n",
    "        top_df['commonIcon'] = common_icon\n",
    "    if not data_df.empty:\n",
    "        data_df['commonIcon'] = common_icon\n",
    "\n",
    "    return top_df, data_df\n",
    "\n",
    "# ---- Process 'new_car_detail' Column ----\n",
    "\n",
    "# Fetch the 'new_car_detail' column only\n",
    "new_car_detail_column = df['new_car_detail']\n",
    "\n",
    "# Apply conversion function to the 'new_car_detail' column\n",
    "new_car_detail_dicts = new_car_detail_column.apply(convert_to_dict)\n",
    "\n",
    "# Flatten each dictionary and convert to DataFrame\n",
    "flattened_df_list = [pd.DataFrame([flatten_dict(d)]) for d in new_car_detail_dicts]\n",
    "flattened_df = pd.concat(flattened_df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_overview' Column ----\n",
    "\n",
    "# Convert the 'new_car_overview' column from string to nested dictionaries\n",
    "df['new_car_overview'] = df['new_car_overview'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Extract and flatten the nested dictionaries\n",
    "df_list = [extract_flatten_dict(d) for d in df['new_car_overview']]\n",
    "df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_feature' Column ----\n",
    "\n",
    "# Convert the 'new_car_feature' column from string to nested dictionaries\n",
    "df['new_car_feature'] = df['new_car_feature'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Apply the flattening function to each row and collect results\n",
    "top_dfs_feature = []\n",
    "data_dfs_feature = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    top_df_feature, data_df_feature = flatten_nested_data(row['new_car_feature'])\n",
    "    top_dfs_feature.append(top_df_feature)\n",
    "    data_dfs_feature.append(data_df_feature)\n",
    "\n",
    "top_combined_feature = pd.concat(top_dfs_feature, ignore_index=True)\n",
    "data_combined_feature = pd.concat(data_dfs_feature, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_specs' Column ----\n",
    "\n",
    "# Initialize a list to collect key-value pairs with an index reference\n",
    "data_records = []\n",
    "\n",
    "# Define the processing function for extracting key-value pairs with an index reference\n",
    "def extract_key_value_pairs(json_data, index):\n",
    "    try:\n",
    "        # Convert JSON-like string into a dictionary\n",
    "        data = json.loads(json_data.replace(\"'\", \"\\\"\"))\n",
    "\n",
    "        # Create a dictionary to hold the values for this record\n",
    "        record = {'index': index}\n",
    "        \n",
    "        # Extract 'top' section key-value pairs\n",
    "        if 'top' in data:\n",
    "            for item in data['top']:\n",
    "                record[item['key']] = item['value']\n",
    "\n",
    "        # Extract 'data' section key-value pairs\n",
    "        if 'data' in data:\n",
    "            for section in data['data']:\n",
    "                for item in section['list']:\n",
    "                    record[item['key']] = item['value']\n",
    "        \n",
    "        # Add the record to the list\n",
    "        data_records.append(record)\n",
    "    \n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error processing JSON data at index {index}: {e}\")\n",
    "\n",
    "# Process only the 'new_car_specs' column\n",
    "if 'new_car_specs' in df.columns:\n",
    "    for index, row in df.iterrows():\n",
    "        json_data = row['new_car_specs']\n",
    "        if pd.notna(json_data):  # Check for NaN values\n",
    "            extract_key_value_pairs(json_data, index)\n",
    "\n",
    "# Create a DataFrame from the list of records\n",
    "records_df = pd.DataFrame(data_records)\n",
    "\n",
    "# Drop the 'index' column as it's not needed in the final output\n",
    "records_df = records_df.drop(columns=['index'], errors='ignore')\n",
    "\n",
    "# ---- Combine All DataFrames Horizontally ----\n",
    "\n",
    "# Reset index for consistency\n",
    "flattened_df.reset_index(drop=True, inplace=True)\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "top_combined_feature.reset_index(drop=True, inplace=True)\n",
    "data_combined_feature.reset_index(drop=True, inplace=True)\n",
    "records_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate all DataFrames horizontally\n",
    "max_len = max(len(flattened_df), len(df_combined), len(top_combined_feature), len(data_combined_feature), len(records_df))\n",
    "\n",
    "# Ensure all DataFrames have the same number of rows by reindexing\n",
    "flattened_df = flattened_df.reindex(range(max_len))\n",
    "df_combined = df_combined.reindex(range(max_len))\n",
    "top_combined_feature = top_combined_feature.reindex(range(max_len))\n",
    "data_combined_feature = data_combined_feature.reindex(range(max_len))\n",
    "records_df = records_df.reindex(range(max_len))\n",
    "\n",
    "# Concatenate horizontally\n",
    "final_df = pd.concat([flattened_df, df_combined, top_combined_feature, data_combined_feature, records_df], axis=1)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv('delhi_cars_output.csv', index=False)\n",
    "\n",
    "print(\"\\nCombined DataFrames have been saved to 'delhi_cars_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2125f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['new_car_detail', 'new_car_overview', 'new_car_feature',\n",
      "       'new_car_specs', 'car_links'],\n",
      "      dtype='object')\n",
      "\n",
      "Combined DataFrames have been saved to 'hyderabad_cars_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('hyderabad_cars.csv')\n",
    "\n",
    "# Display the columns to confirm their presence\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# ---- Helper Functions ----\n",
    "\n",
    "# Function to convert a string to a dictionary\n",
    "def convert_to_dict(value):\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return {}\n",
    "\n",
    "# Function to flatten a dictionary\n",
    "def flatten_dict(d):\n",
    "    flattened = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            for sub_k, sub_v in flatten_dict(v).items():\n",
    "                flattened[f\"{k}_{sub_k}\"] = sub_v\n",
    "        else:\n",
    "            flattened[k] = v\n",
    "    return flattened\n",
    "\n",
    "# Function to extract and flatten the nested 'top' dictionary\n",
    "def extract_flatten_dict(nested_dict):\n",
    "    if 'top' in nested_dict:\n",
    "        top_data = nested_dict['top']\n",
    "        df = pd.DataFrame(top_data)\n",
    "        df = df.drop(columns=['icon'], errors='ignore')\n",
    "        return df.set_index('key').T\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to flatten the nested 'top' and 'data' sections\n",
    "def flatten_nested_data(nested_dict):\n",
    "    # Flatten 'top' section\n",
    "    top_df = pd.DataFrame(nested_dict.get('top', []))\n",
    "    \n",
    "    # Flatten 'data' section\n",
    "    data_list = nested_dict.get('data', [])\n",
    "    data_df_list = []\n",
    "    for category in data_list:\n",
    "        category_df = pd.DataFrame(category.get('list', []))\n",
    "        category_df['heading'] = category.get('heading')\n",
    "        category_df['subHeading'] = category.get('subHeading')\n",
    "        data_df_list.append(category_df)\n",
    "    \n",
    "    data_df = pd.concat(data_df_list, ignore_index=True) if data_df_list else pd.DataFrame()\n",
    "    \n",
    "    # Add commonIcon\n",
    "    common_icon = nested_dict.get('commonIcon', None)\n",
    "    if not top_df.empty:\n",
    "        top_df['commonIcon'] = common_icon\n",
    "    if not data_df.empty:\n",
    "        data_df['commonIcon'] = common_icon\n",
    "\n",
    "    return top_df, data_df\n",
    "\n",
    "# ---- Process 'new_car_detail' Column ----\n",
    "\n",
    "# Fetch the 'new_car_detail' column only\n",
    "new_car_detail_column = df['new_car_detail']\n",
    "\n",
    "# Apply conversion function to the 'new_car_detail' column\n",
    "new_car_detail_dicts = new_car_detail_column.apply(convert_to_dict)\n",
    "\n",
    "# Flatten each dictionary and convert to DataFrame\n",
    "flattened_df_list = [pd.DataFrame([flatten_dict(d)]) for d in new_car_detail_dicts]\n",
    "flattened_df = pd.concat(flattened_df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_overview' Column ----\n",
    "\n",
    "# Convert the 'new_car_overview' column from string to nested dictionaries\n",
    "df['new_car_overview'] = df['new_car_overview'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Extract and flatten the nested dictionaries\n",
    "df_list = [extract_flatten_dict(d) for d in df['new_car_overview']]\n",
    "df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_feature' Column ----\n",
    "\n",
    "# Convert the 'new_car_feature' column from string to nested dictionaries\n",
    "df['new_car_feature'] = df['new_car_feature'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Apply the flattening function to each row and collect results\n",
    "top_dfs_feature = []\n",
    "data_dfs_feature = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    top_df_feature, data_df_feature = flatten_nested_data(row['new_car_feature'])\n",
    "    top_dfs_feature.append(top_df_feature)\n",
    "    data_dfs_feature.append(data_df_feature)\n",
    "\n",
    "top_combined_feature = pd.concat(top_dfs_feature, ignore_index=True)\n",
    "data_combined_feature = pd.concat(data_dfs_feature, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_specs' Column ----\n",
    "\n",
    "# Initialize a list to collect key-value pairs with an index reference\n",
    "data_records = []\n",
    "\n",
    "# Define the processing function for extracting key-value pairs with an index reference\n",
    "def extract_key_value_pairs(json_data, index):\n",
    "    try:\n",
    "        # Convert JSON-like string into a dictionary\n",
    "        data = json.loads(json_data.replace(\"'\", \"\\\"\"))\n",
    "\n",
    "        # Create a dictionary to hold the values for this record\n",
    "        record = {'index': index}\n",
    "        \n",
    "        # Extract 'top' section key-value pairs\n",
    "        if 'top' in data:\n",
    "            for item in data['top']:\n",
    "                record[item['key']] = item['value']\n",
    "\n",
    "        # Extract 'data' section key-value pairs\n",
    "        if 'data' in data:\n",
    "            for section in data['data']:\n",
    "                for item in section['list']:\n",
    "                    record[item['key']] = item['value']\n",
    "        \n",
    "        # Add the record to the list\n",
    "        data_records.append(record)\n",
    "    \n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error processing JSON data at index {index}: {e}\")\n",
    "\n",
    "# Process only the 'new_car_specs' column\n",
    "if 'new_car_specs' in df.columns:\n",
    "    for index, row in df.iterrows():\n",
    "        json_data = row['new_car_specs']\n",
    "        if pd.notna(json_data):  # Check for NaN values\n",
    "            extract_key_value_pairs(json_data, index)\n",
    "\n",
    "# Create a DataFrame from the list of records\n",
    "records_df = pd.DataFrame(data_records)\n",
    "\n",
    "# Drop the 'index' column as it's not needed in the final output\n",
    "records_df = records_df.drop(columns=['index'], errors='ignore')\n",
    "\n",
    "# ---- Combine All DataFrames Horizontally ----\n",
    "\n",
    "# Reset index for consistency\n",
    "flattened_df.reset_index(drop=True, inplace=True)\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "top_combined_feature.reset_index(drop=True, inplace=True)\n",
    "data_combined_feature.reset_index(drop=True, inplace=True)\n",
    "records_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate all DataFrames horizontally\n",
    "max_len = max(len(flattened_df), len(df_combined), len(top_combined_feature), len(data_combined_feature), len(records_df))\n",
    "\n",
    "# Ensure all DataFrames have the same number of rows by reindexing\n",
    "flattened_df = flattened_df.reindex(range(max_len))\n",
    "df_combined = df_combined.reindex(range(max_len))\n",
    "top_combined_feature = top_combined_feature.reindex(range(max_len))\n",
    "data_combined_feature = data_combined_feature.reindex(range(max_len))\n",
    "records_df = records_df.reindex(range(max_len))\n",
    "\n",
    "# Concatenate horizontally\n",
    "final_df = pd.concat([flattened_df, df_combined, top_combined_feature, data_combined_feature, records_df], axis=1)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv('hyderabad_cars_output.csv', index=False)\n",
    "\n",
    "print(\"\\nCombined DataFrames have been saved to 'hyderabad_cars_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8635697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['new_car_detail', 'new_car_overview', 'new_car_feature',\n",
      "       'new_car_specs', 'car_links'],\n",
      "      dtype='object')\n",
      "\n",
      "Combined DataFrames have been saved to 'jaipur_cars_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('jaipur_cars.csv')\n",
    "\n",
    "# Display the columns to confirm their presence\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# ---- Helper Functions ----\n",
    "\n",
    "# Function to convert a string to a dictionary\n",
    "def convert_to_dict(value):\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return {}\n",
    "\n",
    "# Function to flatten a dictionary\n",
    "def flatten_dict(d):\n",
    "    flattened = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            for sub_k, sub_v in flatten_dict(v).items():\n",
    "                flattened[f\"{k}_{sub_k}\"] = sub_v\n",
    "        else:\n",
    "            flattened[k] = v\n",
    "    return flattened\n",
    "\n",
    "# Function to extract and flatten the nested 'top' dictionary\n",
    "def extract_flatten_dict(nested_dict):\n",
    "    if 'top' in nested_dict:\n",
    "        top_data = nested_dict['top']\n",
    "        df = pd.DataFrame(top_data)\n",
    "        df = df.drop(columns=['icon'], errors='ignore')\n",
    "        return df.set_index('key').T\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to flatten the nested 'top' and 'data' sections\n",
    "def flatten_nested_data(nested_dict):\n",
    "    # Flatten 'top' section\n",
    "    top_df = pd.DataFrame(nested_dict.get('top', []))\n",
    "    \n",
    "    # Flatten 'data' section\n",
    "    data_list = nested_dict.get('data', [])\n",
    "    data_df_list = []\n",
    "    for category in data_list:\n",
    "        category_df = pd.DataFrame(category.get('list', []))\n",
    "        category_df['heading'] = category.get('heading')\n",
    "        category_df['subHeading'] = category.get('subHeading')\n",
    "        data_df_list.append(category_df)\n",
    "    \n",
    "    data_df = pd.concat(data_df_list, ignore_index=True) if data_df_list else pd.DataFrame()\n",
    "    \n",
    "    # Add commonIcon\n",
    "    common_icon = nested_dict.get('commonIcon', None)\n",
    "    if not top_df.empty:\n",
    "        top_df['commonIcon'] = common_icon\n",
    "    if not data_df.empty:\n",
    "        data_df['commonIcon'] = common_icon\n",
    "\n",
    "    return top_df, data_df\n",
    "\n",
    "# ---- Process 'new_car_detail' Column ----\n",
    "\n",
    "# Fetch the 'new_car_detail' column only\n",
    "new_car_detail_column = df['new_car_detail']\n",
    "\n",
    "# Apply conversion function to the 'new_car_detail' column\n",
    "new_car_detail_dicts = new_car_detail_column.apply(convert_to_dict)\n",
    "\n",
    "# Flatten each dictionary and convert to DataFrame\n",
    "flattened_df_list = [pd.DataFrame([flatten_dict(d)]) for d in new_car_detail_dicts]\n",
    "flattened_df = pd.concat(flattened_df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_overview' Column ----\n",
    "\n",
    "# Convert the 'new_car_overview' column from string to nested dictionaries\n",
    "df['new_car_overview'] = df['new_car_overview'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Extract and flatten the nested dictionaries\n",
    "df_list = [extract_flatten_dict(d) for d in df['new_car_overview']]\n",
    "df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_feature' Column ----\n",
    "\n",
    "# Convert the 'new_car_feature' column from string to nested dictionaries\n",
    "df['new_car_feature'] = df['new_car_feature'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Apply the flattening function to each row and collect results\n",
    "top_dfs_feature = []\n",
    "data_dfs_feature = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    top_df_feature, data_df_feature = flatten_nested_data(row['new_car_feature'])\n",
    "    top_dfs_feature.append(top_df_feature)\n",
    "    data_dfs_feature.append(data_df_feature)\n",
    "\n",
    "top_combined_feature = pd.concat(top_dfs_feature, ignore_index=True)\n",
    "data_combined_feature = pd.concat(data_dfs_feature, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_specs' Column ----\n",
    "\n",
    "# Initialize a list to collect key-value pairs with an index reference\n",
    "data_records = []\n",
    "\n",
    "# Define the processing function for extracting key-value pairs with an index reference\n",
    "def extract_key_value_pairs(json_data, index):\n",
    "    try:\n",
    "        # Convert JSON-like string into a dictionary\n",
    "        data = json.loads(json_data.replace(\"'\", \"\\\"\"))\n",
    "\n",
    "        # Create a dictionary to hold the values for this record\n",
    "        record = {'index': index}\n",
    "        \n",
    "        # Extract 'top' section key-value pairs\n",
    "        if 'top' in data:\n",
    "            for item in data['top']:\n",
    "                record[item['key']] = item['value']\n",
    "\n",
    "        # Extract 'data' section key-value pairs\n",
    "        if 'data' in data:\n",
    "            for section in data['data']:\n",
    "                for item in section['list']:\n",
    "                    record[item['key']] = item['value']\n",
    "        \n",
    "        # Add the record to the list\n",
    "        data_records.append(record)\n",
    "    \n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error processing JSON data at index {index}: {e}\")\n",
    "\n",
    "# Process only the 'new_car_specs' column\n",
    "if 'new_car_specs' in df.columns:\n",
    "    for index, row in df.iterrows():\n",
    "        json_data = row['new_car_specs']\n",
    "        if pd.notna(json_data):  # Check for NaN values\n",
    "            extract_key_value_pairs(json_data, index)\n",
    "\n",
    "# Create a DataFrame from the list of records\n",
    "records_df = pd.DataFrame(data_records)\n",
    "\n",
    "# Drop the 'index' column as it's not needed in the final output\n",
    "records_df = records_df.drop(columns=['index'], errors='ignore')\n",
    "\n",
    "# ---- Combine All DataFrames Horizontally ----\n",
    "\n",
    "# Reset index for consistency\n",
    "flattened_df.reset_index(drop=True, inplace=True)\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "top_combined_feature.reset_index(drop=True, inplace=True)\n",
    "data_combined_feature.reset_index(drop=True, inplace=True)\n",
    "records_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate all DataFrames horizontally\n",
    "max_len = max(len(flattened_df), len(df_combined), len(top_combined_feature), len(data_combined_feature), len(records_df))\n",
    "\n",
    "# Ensure all DataFrames have the same number of rows by reindexing\n",
    "flattened_df = flattened_df.reindex(range(max_len))\n",
    "df_combined = df_combined.reindex(range(max_len))\n",
    "top_combined_feature = top_combined_feature.reindex(range(max_len))\n",
    "data_combined_feature = data_combined_feature.reindex(range(max_len))\n",
    "records_df = records_df.reindex(range(max_len))\n",
    "\n",
    "# Concatenate horizontally\n",
    "final_df = pd.concat([flattened_df, df_combined, top_combined_feature, data_combined_feature, records_df], axis=1)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv('jaipur_cars_output.csv', index=False)\n",
    "\n",
    "print(\"\\nCombined DataFrames have been saved to 'jaipur_cars_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1a0d731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['new_car_detail', 'new_car_overview', 'new_car_feature',\n",
      "       'new_car_specs', 'car_links'],\n",
      "      dtype='object')\n",
      "\n",
      "Combined DataFrames have been saved to 'kolkata_cars_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('kolkata_cars.csv')\n",
    "\n",
    "# Display the columns to confirm their presence\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# ---- Helper Functions ----\n",
    "\n",
    "# Function to convert a string to a dictionary\n",
    "def convert_to_dict(value):\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return {}\n",
    "\n",
    "# Function to flatten a dictionary\n",
    "def flatten_dict(d):\n",
    "    flattened = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            for sub_k, sub_v in flatten_dict(v).items():\n",
    "                flattened[f\"{k}_{sub_k}\"] = sub_v\n",
    "        else:\n",
    "            flattened[k] = v\n",
    "    return flattened\n",
    "\n",
    "# Function to extract and flatten the nested 'top' dictionary\n",
    "def extract_flatten_dict(nested_dict):\n",
    "    if 'top' in nested_dict:\n",
    "        top_data = nested_dict['top']\n",
    "        df = pd.DataFrame(top_data)\n",
    "        df = df.drop(columns=['icon'], errors='ignore')\n",
    "        return df.set_index('key').T\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to flatten the nested 'top' and 'data' sections\n",
    "def flatten_nested_data(nested_dict):\n",
    "    # Flatten 'top' section\n",
    "    top_df = pd.DataFrame(nested_dict.get('top', []))\n",
    "    \n",
    "    # Flatten 'data' section\n",
    "    data_list = nested_dict.get('data', [])\n",
    "    data_df_list = []\n",
    "    for category in data_list:\n",
    "        category_df = pd.DataFrame(category.get('list', []))\n",
    "        category_df['heading'] = category.get('heading')\n",
    "        category_df['subHeading'] = category.get('subHeading')\n",
    "        data_df_list.append(category_df)\n",
    "    \n",
    "    data_df = pd.concat(data_df_list, ignore_index=True) if data_df_list else pd.DataFrame()\n",
    "    \n",
    "    # Add commonIcon\n",
    "    common_icon = nested_dict.get('commonIcon', None)\n",
    "    if not top_df.empty:\n",
    "        top_df['commonIcon'] = common_icon\n",
    "    if not data_df.empty:\n",
    "        data_df['commonIcon'] = common_icon\n",
    "\n",
    "    return top_df, data_df\n",
    "\n",
    "# ---- Process 'new_car_detail' Column ----\n",
    "\n",
    "# Fetch the 'new_car_detail' column only\n",
    "new_car_detail_column = df['new_car_detail']\n",
    "\n",
    "# Apply conversion function to the 'new_car_detail' column\n",
    "new_car_detail_dicts = new_car_detail_column.apply(convert_to_dict)\n",
    "\n",
    "# Flatten each dictionary and convert to DataFrame\n",
    "flattened_df_list = [pd.DataFrame([flatten_dict(d)]) for d in new_car_detail_dicts]\n",
    "flattened_df = pd.concat(flattened_df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_overview' Column ----\n",
    "\n",
    "# Convert the 'new_car_overview' column from string to nested dictionaries\n",
    "df['new_car_overview'] = df['new_car_overview'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Extract and flatten the nested dictionaries\n",
    "df_list = [extract_flatten_dict(d) for d in df['new_car_overview']]\n",
    "df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_feature' Column ----\n",
    "\n",
    "# Convert the 'new_car_feature' column from string to nested dictionaries\n",
    "df['new_car_feature'] = df['new_car_feature'].apply(lambda x: convert_to_dict(x))\n",
    "\n",
    "# Apply the flattening function to each row and collect results\n",
    "top_dfs_feature = []\n",
    "data_dfs_feature = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    top_df_feature, data_df_feature = flatten_nested_data(row['new_car_feature'])\n",
    "    top_dfs_feature.append(top_df_feature)\n",
    "    data_dfs_feature.append(data_df_feature)\n",
    "\n",
    "top_combined_feature = pd.concat(top_dfs_feature, ignore_index=True)\n",
    "data_combined_feature = pd.concat(data_dfs_feature, ignore_index=True)\n",
    "\n",
    "# ---- Process 'new_car_specs' Column ----\n",
    "\n",
    "# Initialize a list to collect key-value pairs with an index reference\n",
    "data_records = []\n",
    "\n",
    "# Define the processing function for extracting key-value pairs with an index reference\n",
    "def extract_key_value_pairs(json_data, index):\n",
    "    try:\n",
    "        # Convert JSON-like string into a dictionary\n",
    "        data = json.loads(json_data.replace(\"'\", \"\\\"\"))\n",
    "\n",
    "        # Create a dictionary to hold the values for this record\n",
    "        record = {'index': index}\n",
    "        \n",
    "        # Extract 'top' section key-value pairs\n",
    "        if 'top' in data:\n",
    "            for item in data['top']:\n",
    "                record[item['key']] = item['value']\n",
    "\n",
    "        # Extract 'data' section key-value pairs\n",
    "        if 'data' in data:\n",
    "            for section in data['data']:\n",
    "                for item in section['list']:\n",
    "                    record[item['key']] = item['value']\n",
    "        \n",
    "        # Add the record to the list\n",
    "        data_records.append(record)\n",
    "    \n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error processing JSON data at index {index}: {e}\")\n",
    "\n",
    "# Process only the 'new_car_specs' column\n",
    "if 'new_car_specs' in df.columns:\n",
    "    for index, row in df.iterrows():\n",
    "        json_data = row['new_car_specs']\n",
    "        if pd.notna(json_data):  # Check for NaN values\n",
    "            extract_key_value_pairs(json_data, index)\n",
    "\n",
    "# Create a DataFrame from the list of records\n",
    "records_df = pd.DataFrame(data_records)\n",
    "\n",
    "# Drop the 'index' column as it's not needed in the final output\n",
    "records_df = records_df.drop(columns=['index'], errors='ignore')\n",
    "\n",
    "# ---- Combine All DataFrames Horizontally ----\n",
    "\n",
    "# Reset index for consistency\n",
    "flattened_df.reset_index(drop=True, inplace=True)\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "top_combined_feature.reset_index(drop=True, inplace=True)\n",
    "data_combined_feature.reset_index(drop=True, inplace=True)\n",
    "records_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate all DataFrames horizontally\n",
    "max_len = max(len(flattened_df), len(df_combined), len(top_combined_feature), len(data_combined_feature), len(records_df))\n",
    "\n",
    "# Ensure all DataFrames have the same number of rows by reindexing\n",
    "flattened_df = flattened_df.reindex(range(max_len))\n",
    "df_combined = df_combined.reindex(range(max_len))\n",
    "top_combined_feature = top_combined_feature.reindex(range(max_len))\n",
    "data_combined_feature = data_combined_feature.reindex(range(max_len))\n",
    "records_df = records_df.reindex(range(max_len))\n",
    "\n",
    "# Concatenate horizontally\n",
    "final_df = pd.concat([flattened_df, df_combined, top_combined_feature, data_combined_feature, records_df], axis=1)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv('kolkata_cars_output.csv', index=False)\n",
    "\n",
    "print(\"\\nCombined DataFrames have been saved to 'kolkata_cars_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e65ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
